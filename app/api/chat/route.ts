import { NextRequest, NextResponse } from "next/server"
import { prisma } from "@/lib/prisma"
import { getRelevantContext } from "@/lib/pinecone"
import { generateText } from "ai"
import { openai } from "@ai-sdk/openai"
import { CONFIDENCE_THRESHOLD, MAX_CONTEXT_MESSAGES } from "@/types/chat"

// Declare global type for Socket.io
declare global {
  var io: any
}

export async function POST(request: NextRequest) {
  try {
    const body = await request.json()
    const { sessionId, content } = body

    if (!sessionId || !content) {
      return NextResponse.json(
        { error: "sessionId e content s√£o obrigat√≥rios" },
        { status: 400 }
      )
    }

    // Buscar sess√£o existente
    const session = await prisma.chatSession.findUnique({
      where: { id: sessionId },
      include: {
        messages: {
          orderBy: { createdAt: "desc" },
          take: MAX_CONTEXT_MESSAGES,
        },
      },
    })

    if (!session) {
      return NextResponse.json(
        { error: "Sess√£o n√£o encontrada" },
        { status: 404 }
      )
    }

    // Criar mensagem do usu√°rio
    const userMessage = await prisma.chatMessage.create({
      data: {
        sessionId,
        role: "USER",
        content,
      },
    })

    // Buscar configura√ß√µes do chat
    const settingsResponse = await fetch(`${request.nextUrl.origin}/api/chat/settings`, {
      headers: request.headers,
    })
    const settings = await settingsResponse.json()

    // Buscar contexto relevante no Pinecone
    console.log("üîç Buscando contexto relevante para:", content)
    const context = await getRelevantContext(
      content, 
      settings.knowledgeBase?.enabledCategories || undefined, 
      settings.knowledgeBase?.maxContexts || 5
    )
    
    // Preparar hist√≥rico de conversa para contexto
    const conversationHistory = session.messages
      .reverse()
      .map((msg: any) => ({
        role: msg.role.toLowerCase() as "user" | "assistant",
        content: msg.content,
      }))

    // Gerar resposta com OpenAI
    const prompt = `
      Voc√™ √© o assistente virtual inteligente da Kirvano, especializado em suporte ao cliente.
      
      üß† MEM√ìRIA/BASE DE CONHECIMENTO (use como REFER√äNCIA, n√£o copie literalmente):
      ${context || 'Nenhum contexto espec√≠fico encontrado.'}
      
      üí¨ HIST√ìRICO COMPLETO DA CONVERSA:
      ${conversationHistory.map((m: any) => `${m.role === 'user' ? 'üë§ Cliente' : 'ü§ñ Assistente'}: ${m.content}`).join('\n')}
      
      ‚ùì PERGUNTA ATUAL DO CLIENTE:
      ${content}
      
      ‚ö†Ô∏è INSTRU√á√ïES CR√çTICAS - LEIA COM ATEN√á√ÉO:
      
      1. **NUNCA COPIE TEXTOS DA BASE DE CONHECIMENTO**
         - Use as informa√ß√µes como REFER√äNCIA
         - REESCREVA com suas pr√≥prias palavras
         - PERSONALIZE para o contexto ESPEC√çFICO do cliente
         - ADAPTE o tom e conte√∫do para a situa√ß√£o atual
      
      2. **GERE RESPOSTAS NATURAIS E CONTEXTUALIZADAS**
         - Considere o NOME do cliente (se dispon√≠vel)
         - Leve em conta o HIST√ìRICO da conversa
         - Responda de forma CONVERSACIONAL, n√£o rob√≥tica
         - Use varia√ß√µes na linguagem (evite respostas padronizadas)
      
      3. **SEJA ESPEC√çFICO E √öTIL**
         - Se for sobre senha: explique o processo REAL do sistema
         - Se for sobre funcionalidades: descreva de forma pr√°tica
         - Se for sobre problemas: ofere√ßa solu√ß√µes concretas
         - SEMPRE considere o contexto √∫nico da pergunta
      
      4. **FORMATA√á√ÉO DIN√ÇMICA**
         - Use bullet points APENAS quando fizer sentido
         - Varie entre par√°grafos e listas
         - Emojis com modera√ß√£o (1-2 por mensagem no m√°ximo)
         - Adapte o formato ao tipo de pergunta
      
      5. **TRANSPAR√äNCIA E HUMANIZA√á√ÉO**
         - Se n√£o tiver certeza: "Pelo que entendi..."
         - Se precisar confirmar: "Voc√™ est√° se referindo a..."
         - Se for complexo: "Essa √© uma quest√£o importante..."
         - NUNCA invente informa√ß√µes
      
      6. **FINALIZA√á√ÉO CONTEXTUAL**
         - Pergunte algo RELEVANTE ao que foi discutido
         - Ofere√ßa ajuda ESPEC√çFICA relacionada ao t√≥pico
         - Evite finaliza√ß√µes gen√©ricas
      
      üéØ EXEMPLO DO QUE N√ÉO FAZER:
      ‚ùå "Para recuperar sua senha, siga estes passos: 1. Acesse..."
      
      üéØ EXEMPLO DO QUE FAZER:
      ‚úÖ "Entendo sua dificuldade com a senha! Vou te ajudar a recuper√°-la rapidamente. No seu caso..."
      
      üìä AN√ÅLISE OBRIGAT√ìRIA:
      - CONFIAN√áA: Seja realista (0.0 a 1.0)
      - PERGUNTAS: Sugira quest√µes REALMENTE relacionadas
      - ESCALAR: true se precisar de interven√ß√£o humana
      
      üìù FORMATO DA RESPOSTA (N√ÉO MODIFIQUE):
      RESPOSTA: [Sua resposta ORIGINAL e PERSONALIZADA aqui]
      CONFIAN√áA: [0.0 a 1.0]
      PERGUNTAS_RELACIONADAS: [pergunta1|pergunta2|pergunta3]
      ESCALAR: [true/false]
    `

    console.log("üì§ Gerando resposta com OpenAI...")
    const { text } = await generateText({
      model: openai(settings.ai?.model || "gpt-4o"),
      prompt,
      temperature: settings.ai?.temperature || 0.7, // Aumentar temperatura para mais criatividade
      maxTokens: 1000,
    })

    // Extrair informa√ß√µes da resposta
    console.log("üìù Resposta bruta da IA:", text);
    
    let resposta = ""
    let confianca = 0.8
    let perguntasRelacionadas: string[] = []
    let deveEscalar = false

    // Dividir o texto em se√ß√µes
    const sections = text.split('\n');
    let currentSection = '';
    
    for (const line of sections) {
      if (line.startsWith('RESPOSTA:')) {
        currentSection = 'resposta';
        const content = line.substring('RESPOSTA:'.length).trim();
        if (content) resposta = content;
      } else if (line.startsWith('CONFIAN√áA:')) {
        currentSection = 'confianca';
        const value = line.substring('CONFIAN√áA:'.length).trim();
        confianca = parseFloat(value) || 0.8;
      } else if (line.startsWith('PERGUNTAS_RELACIONADAS:')) {
        currentSection = 'perguntas';
        const questions = line.substring('PERGUNTAS_RELACIONADAS:'.length).trim();
        if (questions) {
          perguntasRelacionadas = questions
            .split('|')
            .map(p => p.trim())
            .filter(p => p.length > 0);
        }
      } else if (line.startsWith('ESCALAR:')) {
        currentSection = 'escalar';
        const value = line.substring('ESCALAR:'.length).trim();
        deveEscalar = value === 'true';
      } else if (currentSection === 'resposta' && line.trim()) {
        // Continuar adicionando linhas √† resposta se ainda estamos nessa se√ß√£o
        resposta += '\n' + line;
      }
    }

    // Se n√£o conseguiu extrair a resposta no formato esperado, usar o texto completo
    if (!resposta) {
      console.log("‚ö†Ô∏è Formato de resposta n√£o reconhecido, usando texto completo");
      resposta = text.trim();
    }

    console.log("‚úÖ Resposta extra√≠da:", { 
      resposta: resposta.substring(0, 100) + '...', 
      confianca, 
      perguntasRelacionadas, 
      deveEscalar 
    });

    // Criar mensagem do assistente
    const assistantMessage = await prisma.chatMessage.create({
      data: {
        sessionId,
        role: "ASSISTANT",
        content: resposta,
        confidence: confianca,
        sources: context ? { knowledgeBase: context.substring(0, 1000) } : undefined,
        metadata: {
          suggestedQuestions: perguntasRelacionadas,
          shouldEscalate: deveEscalar || confianca < CONFIDENCE_THRESHOLD,
        },
      },
    })

    // Usar threshold configurado ou padr√£o
    const confidenceThreshold = (settings.ai?.confidenceThreshold || 80) / 100

    // Atualizar status da sess√£o se precisar escalar
    if (deveEscalar || confianca < confidenceThreshold) {
      await prisma.chatSession.update({
        where: { id: sessionId },
        data: { status: "ESCALATED" },
      })

      // Chamar webhook se configurado
      if (settings.advanced?.webhookUrl) {
        try {
          await fetch(settings.advanced.webhookUrl, {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({
              sessionId,
              userMessage: content,
              confidence: confianca,
              reason: deveEscalar ? "ai_suggested" : "low_confidence",
            }),
          })
        } catch (webhookError) {
          console.error("‚ùå Erro ao chamar webhook:", webhookError)
        }
      }
    }

    // Emitir evento via Socket.io para atualiza√ß√£o em tempo real
    const io = global.io
    if (io) {
      io.to(sessionId).emit("new-message", assistantMessage)
    }

    return NextResponse.json({
      message: assistantMessage,
      suggestedQuestions: perguntasRelacionadas,
      shouldEscalate: deveEscalar || confianca < CONFIDENCE_THRESHOLD,
    })
  } catch (error) {
    console.error("‚ùå Erro no chat:", error)
    return NextResponse.json(
      { error: "Erro ao processar mensagem" },
      { status: 500 }
    )
  }
}

// Criar nova sess√£o de chat
export async function PUT(request: NextRequest) {
  try {
    const body = await request.json()
    const { userEmail, userName, userPhone, source = "widget", metadata } = body

    // Validar dados obrigat√≥rios
    if (!userEmail || !userName || !userPhone) {
      return NextResponse.json(
        { error: "Nome, e-mail e telefone s√£o obrigat√≥rios" },
        { status: 400 }
      )
    }

    // Buscar ou criar cliente
    let client = await prisma.client.findFirst({
      where: {
        OR: [
          { email: userEmail },
          { phone: userPhone }
        ]
      }
    })

    if (!client) {
      // Criar novo cliente
      client = await prisma.client.create({
        data: {
          email: userEmail,
          name: userName,
          phone: userPhone,
        }
      })
    } else {
      // Atualizar dados do cliente se necess√°rio
      const updates: any = {}
      if (!client.name && userName) updates.name = userName
      if (!client.phone && userPhone) updates.phone = userPhone
      
      if (Object.keys(updates).length > 0) {
        client = await prisma.client.update({
          where: { id: client.id },
          data: updates
        })
      }
    }

    // Criar ticket para o chat
    const ticket = await prisma.ticket.create({
      data: {
        subject: `Chat iniciado - ${userName}`,
        description: `Chat iniciado em ${new Date().toLocaleString('pt-BR')}`,
        status: "OPEN",
        priority: "MEDIUM",
        source: "chat",
        clientId: client.id,
        category: "Chat Support",
      }
    })

    // Incrementar contador de tickets do cliente
    await prisma.client.update({
      where: { id: client.id },
      data: { totalTickets: { increment: 1 } }
    })

    // Criar sess√£o de chat vinculada ao cliente e ticket
    const session = await prisma.chatSession.create({
      data: {
        userEmail,
        userName,
        userPhone,
        clientId: client.id,
        ticketId: ticket.id,
        source,
        metadata: {
          ...metadata,
          ticketNumber: ticket.number
        },
        status: "ACTIVE",
      },
    })

    // Buscar configura√ß√µes do chat
    const settingsResponse = await fetch(`${request.nextUrl.origin}/api/chat/settings`, {
      headers: request.headers,
    })
    const settings = await settingsResponse.json()

    // Verificar hor√°rio de atendimento
    const now = new Date()
    const currentTime = `${now.getHours().toString().padStart(2, '0')}:${now.getMinutes().toString().padStart(2, '0')}`
    const businessHours = settings.preAttendance?.businessHours
    
    let welcomeContent = settings.preAttendance?.welcomeMessage || "Ol√°! Sou o assistente virtual da Kirvano. Como posso ajud√°-lo hoje?"
    
    if (businessHours && (currentTime < businessHours.start || currentTime > businessHours.end)) {
      welcomeContent = `Ol√°! Nosso hor√°rio de atendimento √© das ${businessHours.start} √†s ${businessHours.end}. Fora deste hor√°rio, nosso assistente virtual est√° dispon√≠vel para ajudar com perguntas frequentes.`
    }

    // Criar mensagem de boas-vindas
    const welcomeMessage = await prisma.chatMessage.create({
      data: {
        sessionId: session.id,
        role: "SYSTEM",
        content: welcomeContent,
        metadata: {
          suggestedQuestions: settings.preAttendance?.initialQuestions || [
            "Como criar uma conta?",
            "Como resetar minha senha?",
            "Como funciona a plataforma?",
          ],
        },
      },
    })

    return NextResponse.json({
      session,
      welcomeMessage,
    })
  } catch (error) {
    console.error("‚ùå Erro ao criar sess√£o:", error)
    return NextResponse.json(
      { error: "Erro ao criar sess√£o de chat" },
      { status: 500 }
    )
  }
}

// Fechar sess√£o de chat
export async function PATCH(request: NextRequest) {
  try {
    const body = await request.json()
    const { sessionId } = body

    if (!sessionId) {
      return NextResponse.json(
        { error: "sessionId √© obrigat√≥rio" },
        { status: 400 }
      )
    }

    const session = await prisma.chatSession.update({
      where: { id: sessionId },
      data: {
        status: "CLOSED",
        closedAt: new Date(),
      },
    })

    return NextResponse.json({ session })
  } catch (error) {
    console.error("‚ùå Erro ao fechar sess√£o:", error)
    return NextResponse.json(
      { error: "Erro ao fechar sess√£o" },
      { status: 500 }
    )
  }
}
